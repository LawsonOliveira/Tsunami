{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving PDEs with PyTorch\n",
    "\n",
    "This file contains our first approach to solve PDEs with neural networks on the PyTorch Library.  \n",
    "We will try to solve the poisson Equation :  \n",
    "$-\\Delta u(x) = f(x)$ on $\\Omega = [0,1]^2$  \n",
    "With Dirichlet homogeneous boundary conditions $u|_{\\partial \\Omega}=0$ and $f(x_1, x_2)=2\\pi^2 sin(\\pi x_1) sin(\\pi x_2)$\n",
    "\n",
    "The loss to minimize here is $\\mathcal{L} = ||\\Delta u(x) + f(x)||_2$, the MSE of the PDE  \n",
    "The true function $u$ should be $u(x_1, x_2)=sin(\\pi x_1) sin(\\pi x_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = 'C:/Users/antie/Documents/Pole_recherche/Tsunami'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = 'C:/Users/Gilles/CS/cours/PoleProjet/FormationRecherche/Tsunami/TP/sceance4/Tsunami'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "#print(os.getcwd())\n",
    "#os.chdir(__file__)\n",
    "#print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\") # Specify GPU Usage for computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 2 # Input size, corresponds to antecedent space dimension\n",
    "learning_rate = 0.005 # Parameter for Adam optimizer\n",
    "training_steps = 1000 # Epoch computed\n",
    "n_neurons = 5 # number of neurons in the hidden layers\n",
    "report_steps = training_steps//100 # How often is the loss printed during training\n",
    "grid_length = 40 # Length of the square grid considered for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define neural network structure\n",
    "\n",
    "Here we consider a perceptron with 2 hidden layers of 10 nodes, with n_input inputs and 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=5, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=5, out_features=5, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "multilayer_perceptron = nn.Sequential(\n",
    "    nn.Linear(n_input, n_neurons),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(n_neurons, n_neurons),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(n_neurons, 1)\n",
    ")\n",
    "\n",
    "print(multilayer_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universal Approximator, using the paper from 1997, with A and F placeholders\n",
    "def compute_g(x):\n",
    "  nn_x = multilayer_perceptron(x)\n",
    "  A = 0\n",
    "  F = 1\n",
    "  return nn_x*F + A\n",
    "\n",
    "# Given EDO\n",
    "def compute_f(x):\n",
    "  return 2*np.pi**2*np.sin(np.pi*x[:,0])*np.sin(np.pi*x[:,1])\n",
    "\n",
    "# Loss function\n",
    "loss_fct = nn.MSELoss()    \n",
    "optimizer = torch.optim.Adam(multilayer_perceptron.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code taken from https://discuss.pytorch.org/t/how-to-calculate-laplacian-for-multiple-batches-in-parallel/104888\n",
    "# Computes the laplacian for a batch, to use in the loss calculation\n",
    "\n",
    "def calculate_laplacian(model, tensor: torch.tensor):\n",
    "    \"\"\"\n",
    "    Laplacian (= sum of 2nd derivations)\n",
    "     of (evaluated) nd->1d-function fx w.r.t. nd-tensor x\n",
    "    :rtype: torch.Tensor\n",
    "    \"\"\"\n",
    "    laplacian = torch.zeros(tensor.shape[0]) #array to store values of laplacian\n",
    "\n",
    "    for i, tensori in enumerate(tensor):\n",
    "        hess = torch.autograd.functional.hessian(model, tensori.unsqueeze(0), create_graph=True)\n",
    "        laplacian[i] = torch.diagonal(hess.view(n_input, n_input), offset=0).sum()\n",
    "    \n",
    "    return laplacian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the grid on which to train the neural network  \n",
    "We sample $\\Omega = [0,1]^2$ with grid_length² uniformely distributed points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0000, 0.0256],\n",
      "        [0.0000, 0.0513],\n",
      "        ...,\n",
      "        [1.0000, 0.9487],\n",
      "        [1.0000, 0.9744],\n",
      "        [1.0000, 1.0000]])\n",
      "torch.Size([1600, 2])\n"
     ]
    }
   ],
   "source": [
    "x = np.linspace(0, 1, grid_length)\n",
    "y = np.linspace(0, 1, grid_length)\n",
    "\n",
    "# Put the training points and values in tensors\n",
    "z = np.array([[u,v] for u in x for v in y])\n",
    "z_values = torch.FloatTensor(compute_f(z)).unsqueeze(1) # Values in tensor, unsqueeze allows to go from [10000] to [10000, 1]\n",
    "z_training = torch.FloatTensor(z) # put in tensor to allow pytorch calculation\n",
    "print(z_training)\n",
    "print(z_training.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch n°10:  92.5995101928711\n",
      "Epoch n°20:  92.5995101928711\n",
      "Epoch n°30:  92.5995101928711\n",
      "Epoch n°40:  92.5995101928711\n",
      "Epoch n°50:  92.5995101928711\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:/Users/antie/Documents/Pole_recherche/Tsunami\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultilayer_perceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_training\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# Output du réseau de neurones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcalculate_laplacian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmultilayer_perceptron\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_values\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# On calcule la loss nécéssaire\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:/Users/antie/Documents/Pole_recherche/Tsunami\u001b[0m in \u001b[0;36mcalculate_laplacian\u001b[1;34m(model, tensor)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensori\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mhess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhessian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensori\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mlaplacian\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\antie\\anaconda3\\lib\\site-packages\\torch\\autograd\\functional.py\u001b[0m in \u001b[0;36mhessian\u001b[1;34m(func, inputs, create_graph, strict, vectorize, outer_jacobian_strategy)\u001b[0m\n\u001b[0;32m    805\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m     res = jacobian(jac_func, inputs, create_graph=create_graph, strict=strict, vectorize=vectorize,\n\u001b[0m\u001b[0;32m    808\u001b[0m                    strategy=outer_jacobian_strategy)\n\u001b[0;32m    809\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_tuple_postprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mis_inputs_tuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_inputs_tuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\antie\\anaconda3\\lib\\site-packages\\torch\\autograd\\functional.py\u001b[0m in \u001b[0;36mjacobian\u001b[1;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_grad_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneed_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m         is_outputs_tuple, outputs = _as_tuple(outputs,\n\u001b[0;32m    576\u001b[0m                                               \u001b[1;34m\"outputs of the user-provided function\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\antie\\anaconda3\\lib\\site-packages\\torch\\autograd\\functional.py\u001b[0m in \u001b[0;36mjac_func\u001b[1;34m(*inp)\u001b[0m\n\u001b[0;32m    801\u001b[0m             \u001b[1;31m# or else the input will be detached\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m             \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m         \u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_single_output_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    804\u001b[0m         \u001b[0m_check_requires_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"jacobian\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\antie\\anaconda3\\lib\\site-packages\\torch\\autograd\\functional.py\u001b[0m in \u001b[0;36mjacobian\u001b[1;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_grad_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneed_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m         is_outputs_tuple, outputs = _as_tuple(outputs,\n\u001b[0;32m    576\u001b[0m                                               \u001b[1;34m\"outputs of the user-provided function\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\antie\\anaconda3\\lib\\site-packages\\torch\\autograd\\functional.py\u001b[0m in \u001b[0;36mensure_single_output_function\u001b[1;34m(*inp)\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The Tensor returned by the function given to hessian should contain a single element\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mjac_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "multilayer_perceptron.train(True)\n",
    "\n",
    "for epoch in range(training_steps):\n",
    "    optimizer.zero_grad()   # On réinitialise les gradients entre chaque epoch\n",
    "\n",
    "    output = multilayer_perceptron(z_training)   # Output du réseau de neurones\n",
    "    loss = loss_fct(-1*calculate_laplacian(multilayer_perceptron, z_training).unsqueeze(1), z_values)    # On calcule la loss nécéssaire\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch%report_steps==report_steps-1:\n",
    "        print(\"Epoch n°{}: \".format(epoch+1), loss.item())\n",
    "    if loss.item()<1e-5:\n",
    "        break #Stop the iterations if we converge to the solution with MSE less than 1e-5\n",
    "\n",
    "    \n",
    "multilayer_perceptron.train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Random sampling of points on which to display the approximated function\n",
    "x_noisy = x + (np.random.rand(grid_length)-0.5)/grid_length\n",
    "y_noisy = y + (np.random.rand(grid_length)-0.5)/grid_length\n",
    "z_validation = multilayer_perceptron(torch.FloatTensor(np.array([[u,v] for u in x_noisy for v in y_noisy])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 40.0, 0.0, 40.0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolormesh(torch.reshape(z_validation, (grid_length, grid_length)).detach().numpy(), cmap=\"seismic\")\n",
    "plt.colorbar()\n",
    "plt.axis(\"square\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mC:/Users/Gilles/CS/cours/PoleProjet/FormationRecherche/Tsunami/TP/sceance4/Tsunami\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mZ_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultilayer_perceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_validation\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mZ_values\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Error with respect to true function\n",
    "\"\"\"\n",
    "plt.figure()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dfbe69d09349a49120ff36b7a9d7a3d6297f4f930536f8fd166c745a423a6004"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
