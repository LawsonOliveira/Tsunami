epoch: 1
epoch: 1 train step: 0 loss: 0.01378971
epoch: 1 train step: 50 loss: 0.014394347
epoch: 1 train step: 100 loss: 0.014075413
epoch: 1 train step: 150 loss: 0.01385132
epoch: 1 train step: 200 loss: 0.013536813
epoch: 1 train step: 250 loss: 0.01385651
epoch: 1 train step: 300 loss: 0.0140110105
epoch: 1 train step: 350 loss: 0.013237191
epoch: 1 train step: 400 loss: 0.013039298
epoch: 1 train step: 450 loss: 0.013260829
epoch: 1 train step: 500 loss: 0.0130052315
epoch: 1 train step: 550 loss: 0.012647252
epoch: 1 train step: 600 loss: 0.013116915
epoch: 1 train step: 650 loss: 0.012629131
epoch: 1 train step: 700 loss: 0.012692548
epoch: 1 train step: 750 loss: 0.012658246
epoch: 1 train step: 800 loss: 0.011958435
epoch: 1 train step: 850 loss: 0.012465154
epoch: 1 train step: 900 loss: 0.012253743
epoch: 1 train step: 950 loss: 0.012345467
epoch: 1 train step: 1000 loss: 0.012087546
epoch: 1 train step: 1050 loss: 0.012360875
epoch: 1 train step: 1100 loss: 0.012216577
epoch: 1 train step: 1150 loss: 0.012068264
epoch: 1 train step: 1200 loss: 0.011808015
epoch: 1 train step: 1250 loss: 0.011850015
epoch: 1 train step: 1300 loss: 0.012138077
epoch: 1 train step: 1350 loss: 0.011524782
epoch: 1 train step: 1400 loss: 0.011297405
epoch: 1 train step: 1450 loss: 0.012187386
epoch: 1 train step: 1500 loss: 0.011701407
epoch: 1 train step: 1550 loss: 0.011936694
epoch: 1 train step: 1600 loss: 0.011216444
epoch: 1 train step: 1650 loss: 0.0122342715
epoch: 1 train step: 1700 loss: 0.011849184
epoch: 1 train step: 1750 loss: 0.011937848
epoch: 1 train step: 1800 loss: 0.011656541
epoch: 1 train step: 1850 loss: 0.011610471
epoch: 1 train step: 1900 loss: 0.011791743
epoch: 1 train step: 1950 loss: 0.011555111
epoch: 1 train step: 2000 loss: 0.012069483
epoch: 1 train step: 2050 loss: 0.011763259
epoch: 1 train step: 2100 loss: 0.0120144
epoch: 1 train step: 2150 loss: 0.011826595
epoch: 1 train step: 2200 loss: 0.0114409905
epoch: 1 train step: 2250 loss: 0.0121141095
epoch: 1 train step: 2300 loss: 0.012238927
epoch: 1 train step: 2350 loss: 0.011781059
epoch: 1 train step: 2400 loss: 0.012087604
epoch: 1 train step: 2450 loss: 0.0122070685
epoch: 1 train step: 2500 loss: 0.011958316
epoch: 1 train step: 2550 loss: 0.011566957
epoch: 1 train step: 2600 loss: 0.0120198885
epoch: 1 train step: 2650 loss: 0.011883156
epoch: 1 train step: 2700 loss: 0.011827414
epoch: 1 train step: 2750 loss: 0.012063901
epoch: 1 train step: 2800 loss: 0.011937028
epoch: 1 train step: 2850 loss: 0.011368098
epoch: 1 train step: 2900 loss: 0.011424135
epoch: 1 train step: 2950 loss: 0.011269615
epoch: 1 train step: 3000 loss: 0.011674578
epoch: 1 train step: 3050 loss: 0.011430722
epoch: 1 train step: 3100 loss: 0.011522401
epoch: 1 train step: 3150 loss: 0.011623422
epoch: 1 train step: 3200 loss: 0.01192233
epoch: 1 train step: 3250 loss: 0.011502309
epoch: 1 train step: 3300 loss: 0.011575703
epoch: 1 train step: 3350 loss: 0.011651327
epoch: 1 train step: 3400 loss: 0.0118557345
epoch: 1 train step: 3450 loss: 0.01144715
epoch: 1 train step: 3500 loss: 0.011534698
epoch: 1 train step: 3550 loss: 0.012145065
epoch: 1 train step: 3600 loss: 0.011936282
epoch: 1 train step: 3650 loss: 0.011562707
epoch: 1 train step: 3700 loss: 0.011714209
epoch: 1 train step: 3750 loss: 0.0119162705
epoch: 1 train step: 3800 loss: 0.0117653515
epoch: 1 train step: 3850 loss: 0.011724671
epoch: 1 train step: 3900 loss: 0.011616914
epoch: 1 train step: 3950 loss: 0.011906484
epoch: 1 train step: 4000 loss: 0.0114675155
epoch: 1 train step: 4050 loss: 0.01168292
epoch: 1 train step: 4100 loss: 0.011314018
epoch: 1 train step: 4150 loss: 0.0114541035
epoch: 1 train step: 4200 loss: 0.011903493
epoch: 1 train step: 4250 loss: 0.011303628
epoch: 1 train step: 4300 loss: 0.011632833
epoch: 1 train step: 4350 loss: 0.011601454
epoch: 1 train step: 4400 loss: 0.011503703
epoch: 1 train step: 4450 loss: 0.011278158
epoch: 1 train step: 4500 loss: 0.011365538
config:
 {'trial_id': 1, 'remark': '', 'config_training': {'epochs_max': 1, 'n_trains': 5000, 'batch_size': 8192, 'val_size': 8192, 'display_step': 50, 'tol': 1e-06, 'patience': 50}, 'config_model': {'l_units': [30, 30], 'noise': 0, 'learning_rate': {'lr_max': 1e-06, 'lr_min': 1e-10, 'scheduler': 0}, 'optimizer': 'Adam', 'save_path': 'differentiate/hypertuning/byHand/trial_100/model_poisson_trial_100_epoch_2_val_mae_0.408173.h5'}}