{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sympy as sm\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.  4.]\n",
      " [ 9. 16.]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[2. 0.]\n",
      "  [0. 4.]]\n",
      "\n",
      " [[6. 0.]\n",
      "  [0. 8.]]], shape=(2, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as g:\n",
    "  x = tf.constant([[1., 2.], [3., 4.]], dtype=tf.float32)\n",
    "  g.watch(x)\n",
    "  y = x * x\n",
    "  print(y)\n",
    "batch_jacobian = g.batch_jacobian(y, x)\n",
    "print(batch_jacobian)\n",
    "# batch_jacobian is [[[2,  0], [0,  4]], [[6,  0], [0,  8]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 2)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "previous_shape: (5, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TensorShape([5, 2]), TensorShape([5, 2])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dim = 2\n",
    "dim = 1\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(shape=[dim]))\n",
    "model.add(keras.layers.Dense(output_dim))\n",
    "model.summary()\n",
    "\n",
    "X = tf.random.uniform((5,dim),0,1,dtype=np.float32)\n",
    "\n",
    "@tf.function\n",
    "def differentiate(model, X, training=False):\n",
    "    with tf.GradientTape() as tape:\n",
    "        x1 = X[:, 0:1]\n",
    "        tape.watch(x1)\n",
    "        u = model(tf.stack([x1[:, 0]], axis=1), training=training)\n",
    "    du_dx = tf.squeeze(tape.batch_jacobian(u, x1))\n",
    "    del tape\n",
    "    print('previous_shape:', du_dx.shape)\n",
    "    du_dx = tf.reshape(du_dx, (X.shape[0],u.shape[-1]))\n",
    "    return u, du_dx\n",
    "\n",
    "[differentiate(model,X)[i].shape for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 2)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(5, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TensorShape([5, 2]),\n",
       " TensorShape([5, 2]),\n",
       " TensorShape([5, 2]),\n",
       " TensorShape([5, 2]),\n",
       " TensorShape([5, 2])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dim = 2\n",
    "dim = 2\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(shape=[dim]))\n",
    "model.add(keras.layers.Dense(output_dim))\n",
    "model.summary()\n",
    "\n",
    "X = tf.random.uniform((5,dim),0,1,dtype=np.float32)\n",
    "@tf.function\n",
    "def differentiate(model, x, training=False):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        x1 = x[:, 0:1]\n",
    "        tape.watch(x1)\n",
    "        x2= x[:, 1:2]\n",
    "        tape.watch(x2)\n",
    "        # print(model(tf.stack([x1[:, 0],x2[:,0]], axis=1), training=training))\n",
    "        u = model(tf.stack([x1[:, 0],x2[:,0]], axis=1), training=training)\n",
    "        du_dx = tape.batch_jacobian(u, x1)\n",
    "        du_dy = tape.batch_jacobian(u, x2)\n",
    "    # print(u)\n",
    "    # print(du_dx)\n",
    "    du_dxx = tape.batch_jacobian(du_dx, x1)\n",
    "    # print(\"du_dxx\\n\",du_dxx.shape)\n",
    "    du_dyy = tape.batch_jacobian(du_dy, x2)\n",
    "    del tape\n",
    "    print(x.shape)\n",
    "\n",
    "    du_dxx = tf.reshape(du_dxx,shape=[x.shape[0],u.shape[-1]])\n",
    "    du_dyy = tf.reshape(du_dyy,shape=[x.shape[0],u.shape[-1]])\n",
    "    du_dx = tf.reshape(du_dx,shape=[x.shape[0],u.shape[-1]])\n",
    "    du_dy = tf.reshape(du_dy,shape=[x.shape[0],u.shape[-1]])\n",
    "    return u, du_dx, du_dxx, du_dy, du_dyy\n",
    "\n",
    "[differentiate(model,X)[i].shape for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_29 (Dense)            (None, 2)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "der0;\n",
      " tf.Tensor(\n",
      "[[0.45608413]\n",
      " [0.45608413]\n",
      " [0.45608413]\n",
      " [0.45608413]\n",
      " [0.45608413]], shape=(5, 1), dtype=float32)\n",
      "der1\n",
      " tf.Tensor(\n",
      "[[0.143543]\n",
      " [0.143543]\n",
      " [0.143543]\n",
      " [0.143543]\n",
      " [0.143543]], shape=(5, 1), dtype=float32)\n",
      "der_jac\n",
      " tf.Tensor(\n",
      "[[0.45608413 0.143543  ]\n",
      " [0.45608413 0.143543  ]\n",
      " [0.45608413 0.143543  ]\n",
      " [0.45608413 0.143543  ]\n",
      " [0.45608413 0.143543  ]], shape=(5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "output_dim = 2\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(shape=[1]))\n",
    "model.add(keras.layers.Dense(output_dim))\n",
    "model.summary()\n",
    "dim = 2\n",
    "X = tf.random.uniform((5,dim),0,1,dtype=np.float32)\n",
    "with tf.GradientTape(persistent=True) as g:\n",
    "    x1 = X[:,0:1]\n",
    "    g.watch(x1)\n",
    "    y = model(tf.stack([x1[:, 0]], axis=1))\n",
    "    # print(\"y\\n\",y)\n",
    "    y0 = y[:,0]\n",
    "    if output_dim>=2:\n",
    "        y1 = y[:,1]\n",
    "der = g.gradient(y,x1)\n",
    "der0 = g.gradient(y0,x1)\n",
    "print(\"der0;\\n\",der0)\n",
    "if output_dim>=2:\n",
    "    der1 = g.gradient(y1,x1)\n",
    "    print(\"der1\\n\",der1)\n",
    "der_jac = tf.squeeze(g.batch_jacobian(y,x1))\n",
    "if output_dim==1:\n",
    "    der_jac = tf.expand_dims(der_jac,axis=-1)\n",
    "del g\n",
    "# print(\"der\\n\",der)\n",
    "\n",
    "print(\"der_jac\\n\",der_jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.2520027, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "update_state() missing 1 required positional argument: 'y_pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jtros\\CS\\cours\\PoleProjet\\FormationRecherche\\Tsunami\\TP\\sceance4\\Tsunami\\Neural_Networks\\Tensorflow\\test.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jtros/CS/cours/PoleProjet/FormationRecherche/Tsunami/TP/sceance4/Tsunami/Neural_Networks/Tensorflow/test.ipynb#ch0000005?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(loss)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jtros/CS/cours/PoleProjet/FormationRecherche/Tsunami/TP/sceance4/Tsunami/Neural_Networks/Tensorflow/test.ipynb#ch0000005?line=5'>6</a>\u001b[0m metric \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mMeanSquaredError(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m,dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jtros/CS/cours/PoleProjet/FormationRecherche/Tsunami/TP/sceance4/Tsunami/Neural_Networks/Tensorflow/test.ipynb#ch0000005?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(metric(res))\n",
      "File \u001b[1;32mc:\\Users\\jtros\\CS\\cours\\PoleProjet\\FormationRecherche\\Tsunami\\TP\\sceance4\\Tsunami\\venv_tsunami\\lib\\site-packages\\keras\\metrics\\base_metric.py:200\u001b[0m, in \u001b[0;36mMetric.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[39mreturn\u001b[39;00m result_t\n\u001b[0;32m    199\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistribute\u001b[39;00m \u001b[39mimport\u001b[39;00m distributed_training_utils  \u001b[39m# pylint:disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[39mreturn\u001b[39;00m distributed_training_utils\u001b[39m.\u001b[39mcall_replica_local_fn(\n\u001b[0;32m    201\u001b[0m     replica_local_fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jtros\\CS\\cours\\PoleProjet\\FormationRecherche\\Tsunami\\TP\\sceance4\\Tsunami\\venv_tsunami\\lib\\site-packages\\keras\\distribute\\distributed_training_utils.py:60\u001b[0m, in \u001b[0;36mcall_replica_local_fn\u001b[1;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m   \u001b[39mwith\u001b[39;00m strategy\u001b[39m.\u001b[39mscope():\n\u001b[0;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m strategy\u001b[39m.\u001b[39mextended\u001b[39m.\u001b[39mcall_for_each_replica(fn, args, kwargs)\n\u001b[1;32m---> 60\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jtros\\CS\\cours\\PoleProjet\\FormationRecherche\\Tsunami\\TP\\sceance4\\Tsunami\\venv_tsunami\\lib\\site-packages\\keras\\metrics\\base_metric.py:181\u001b[0m, in \u001b[0;36mMetric.__call__.<locals>.replica_local_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m   update_op \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m   update_op \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_state(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    182\u001b[0m update_ops \u001b[39m=\u001b[39m []\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m update_op \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jtros\\CS\\cours\\PoleProjet\\FormationRecherche\\Tsunami\\TP\\sceance4\\Tsunami\\venv_tsunami\\lib\\site-packages\\keras\\utils\\metrics_utils.py:70\u001b[0m, in \u001b[0;36mupdate_state_wrapper.<locals>.decorated\u001b[1;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mTrying to run metric.update_state in replica context when \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     66\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mthe metric was not created in TPUStrategy scope. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     67\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mMake sure the keras Metric is created in TPUstrategy scope. \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[39mwith\u001b[39;00m tf_utils\u001b[39m.\u001b[39mgraph_context_for_symbolic_tensors(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 70\u001b[0m   update_op \u001b[39m=\u001b[39m update_state_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     71\u001b[0m \u001b[39mif\u001b[39;00m update_op \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# update_op will be None in eager execution.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m   metric_obj\u001b[39m.\u001b[39madd_update(update_op)\n",
      "File \u001b[1;32mc:\\Users\\jtros\\CS\\cours\\PoleProjet\\FormationRecherche\\Tsunami\\TP\\sceance4\\Tsunami\\venv_tsunami\\lib\\site-packages\\keras\\metrics\\base_metric.py:140\u001b[0m, in \u001b[0;36mMetric.__new__.<locals>.update_state_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m control_status \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[0;32m    138\u001b[0m ag_update_state \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m    139\u001b[0m     obj_update_state, control_status)\n\u001b[1;32m--> 140\u001b[0m \u001b[39mreturn\u001b[39;00m ag_update_state(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jtros\\CS\\cours\\PoleProjet\\FormationRecherche\\Tsunami\\TP\\sceance4\\Tsunami\\venv_tsunami\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\jtros\\CS\\cours\\PoleProjet\\FormationRecherche\\Tsunami\\TP\\sceance4\\Tsunami\\venv_tsunami\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\jtros\\CS\\cours\\PoleProjet\\FormationRecherche\\Tsunami\\TP\\sceance4\\Tsunami\\venv_tsunami\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "\u001b[1;31mTypeError\u001b[0m: update_state() missing 1 required positional argument: 'y_pred'"
     ]
    }
   ],
   "source": [
    "res = tf.random.uniform((5,2),0,1)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(res))\n",
    "print(loss)\n",
    "\n",
    "metric = tf.keras.metrics.MeanSquaredError(name='mse',dtype=None)\n",
    "print(metric(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.60068214 -4.3473434 ]\n",
      " [ 0.20199859 -8.657986  ]\n",
      " [ 0.5060885  -9.515091  ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf_sample_coords = tf.random.uniform((3, 2), [0,-10], [1,-1])\n",
    "print(tf_sample_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.18454349 -9.317633  ]\n",
      " [ 0.5498848  -9.422832  ]\n",
      " [ 0.46530843 -9.1609745 ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf_sample_coords2 = tf.random.uniform((3, 2), [0,-10], [1,-9])\n",
    "print(tf_sample_coords2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.random.uniform((3,1),0,1)\n",
    "Y = tf.random.uniform((3,1),-10,9)\n",
    "tf_sample_coords = tf.concat([X,Y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed here\n",
      "exp(-3*x/5 - 1/5)*sin(9*x**2 + 1)\n",
      "exp(-y/5 - 3/5)*sin(y + 9)\n",
      "first_part:\n",
      " x*exp(-y/5 - 3/5)*sin(y + 9) + (1 - x)*exp(-y/5)*sin(y)\n",
      "bottom: -0.449328964117222*x*sin(10) - 0.818730753077982*(1 - x)*sin(1) + exp(-3*x/5 - 1/5)*sin(9*x**2 + 1)\n",
      "expr_A:\n",
      " x*exp(-y/5 - 3/5)*sin(y + 9) + y*(-0.449328964117222*x*sin(10) - 0.818730753077982*(1 - x)*sin(1) + exp(-3*x/5 - 1/5)*sin(9*x**2 + 1)) + (1 - x)*exp(-y/5)*sin(y) + (1 - y)*(-0.548811636094026*x*sin(9) + exp(-3*x/5)*sin(9*x**2))\n",
      "(10,)\n",
      "(10, 1)\n",
      "tf.Tensor(\n",
      "[[ 0.0000000e+00]\n",
      " [ 0.0000000e+00]\n",
      " [ 5.9604645e-08]\n",
      " [ 1.1920929e-07]\n",
      " [ 0.0000000e+00]\n",
      " [ 5.9604645e-08]\n",
      " [ 0.0000000e+00]\n",
      " [-2.9802322e-08]\n",
      " [ 0.0000000e+00]\n",
      " [ 2.9802322e-08]], shape=(10, 1), dtype=float32)\n",
      "1.1920929e-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = sm.symbols(\"x,y\")\n",
    "\n",
    "def expr_A():\n",
    "    print('passed here')\n",
    "    def expr_f_0(y):\n",
    "        return sm.exp(-y/5)*sm.sin(y)\n",
    "    def expr_f_1(y):\n",
    "        return sm.exp(-(a+y)/5)*sm.sin(a**2+y)\n",
    "    def expr_g_0(x):\n",
    "        return sm.exp(-(a*x)/5)*sm.sin((a*x)**2)\n",
    "    def expr_g_1(x):\n",
    "        return sm.exp(-(a*x+1)/5)*sm.sin((a*x)**2+1)\n",
    "    # print(expr_g_1(x))\n",
    "    # print(expr_f_1(y))\n",
    "    # first_part = (1-x)*expr_f_0(y)+x*expr_f_1(y)\n",
    "    # print('first_part:\\n',first_part)\n",
    "    # second_part = (1-y)*(expr_g_0(x)-((1-x)*expr_g_0(0)+x*expr_g_0(1))+y*(expr_g_1(x)-((1-x)*expr_g_1(0)+x*expr_g_1(1))))\n",
    "    # bottom = (expr_g_1(x)-((1-x)*expr_g_1(0)+x*expr_g_1(1)))\n",
    "    # print('bottom:',bottom)\n",
    "    return (1-x)*expr_f_0(y)+x*expr_f_1(y)+(1-y)*(expr_g_0(x)-((1-x)*expr_g_0(0)+x*expr_g_0(1)))+y*(expr_g_1(x)-((1-x)*expr_g_1(0)+x*expr_g_1(1)))\n",
    "\n",
    "expr_A = expr_A()\n",
    "print(\"expr_A:\\n\",expr_A)\n",
    "expr_A = sm.lambdify([x, y], sm.Matrix([expr_A]), 'numpy')\n",
    "\n",
    "def evaluate_A(X):\n",
    "    A = tf.expand_dims(tf.squeeze(expr_A(X[:, 0], X[:, 1])), axis=-1)\n",
    "    A = tf.cast(A, dtype=DTYPE)\n",
    "    return A\n",
    "\n",
    "\n",
    "a = 3\n",
    "DTYPE = np.float32\n",
    "@tf.function\n",
    "def true_function(X):\n",
    "    return tf.exp(-(a*X[:, 0]+X[:, 1])/5)*tf.sin(a**2*X[:, 0]**2+X[:, 1])\n",
    "\n",
    "batch_size = 10\n",
    "line = tf.cast(tf.reshape(np.linspace(0,1,num=batch_size,endpoint=True),(batch_size,1)),dtype=DTYPE)\n",
    "boundary_L = tf.concat([tf.zeros((batch_size,1),dtype=DTYPE),line],axis=1)\n",
    "boundary_R = tf.concat([tf.ones((batch_size,1),dtype=DTYPE),line],axis=1)\n",
    "boundary_up = tf.concat([line,tf.ones((batch_size,1),dtype=DTYPE)],axis=1)\n",
    "boundary_bot = tf.concat([line,tf.zeros((batch_size,1),dtype=DTYPE)],axis=1)\n",
    "# true_function(boundary_L)-evaluate_A(boundary_L)\n",
    "test_boundary = boundary_bot\n",
    "print(true_function(test_boundary).shape)\n",
    "print(evaluate_A(test_boundary).shape)\n",
    "error = tf.expand_dims(true_function(test_boundary),-1)-evaluate_A(test_boundary)\n",
    "print(error)\n",
    "print(np.max(error))\n",
    "plt.plot(test_boundary[:,1].numpy(),error)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dexpr_A_dyy(X[:, 0], X[:, 1]):\n",
      " (1, 1)\n",
      "tf.Tensor(\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x,y = sm.symbols(\"x,y\")\n",
    "dim = 2\n",
    "X = tf.random.uniform((5,dim),0,1,dtype=np.float32)\n",
    "pi = np.pi\n",
    "DTYPE = np.float32\n",
    "\n",
    "def expr_A():\n",
    "    def expr_f_0(y):\n",
    "        return 0\n",
    "\n",
    "    def expr_f_1(y):\n",
    "        return 0\n",
    "\n",
    "    def expr_g_0(x):\n",
    "        return 0\n",
    "\n",
    "    def expr_g_1(x):\n",
    "        return 2*sm.sin(pi*x)\n",
    "    if True:\n",
    "        return (1-x)*expr_f_0(y)+x*expr_f_1(y)+expr_g_0(x)-((1-x)*expr_g_0(0)+x*expr_g_0(1))+y*(expr_g_1(x)-((1-x)*expr_g_1(0)+x*expr_g_1(1)))\n",
    "    else:\n",
    "        return (1-x)*expr_f_0(y)+x*expr_f_1(y)+(1-y)*(expr_g_0(x)-((1-x)*expr_g_0(0)+x*expr_g_0(1)))+y*(expr_g_1(x)-((1-x)*expr_g_1(0)+x*expr_g_1(1)))\n",
    "\n",
    "\n",
    "expr_A = expr_A()\n",
    "dexpr_A_dx = sm.diff(expr_A, x, 1)\n",
    "dexpr_A_dxx = sm.diff(dexpr_A_dx, x, 1)\n",
    "dexpr_A_dy = sm.diff(expr_A, y, 1)\n",
    "dexpr_A_dyy = sm.diff(dexpr_A_dy, y, 1)\n",
    "\n",
    "\n",
    "# remark: You can forget a no lambdified expression => here we greatly avoid 'for' loops\n",
    "\n",
    "expr_A = sm.lambdify([x, y], sm.Matrix([expr_A]), 'numpy')\n",
    "dexpr_A_dx = sm.lambdify([x, y], sm.Matrix([dexpr_A_dx]), 'numpy')\n",
    "dexpr_A_dxx = sm.lambdify([x, y], sm.Matrix([dexpr_A_dxx]), 'numpy')\n",
    "dexpr_A_dy = sm.lambdify([x, y], sm.Matrix([dexpr_A_dy]), 'numpy')\n",
    "dexpr_A_dyy = sm.lambdify([x, y], sm.Matrix([dexpr_A_dyy]), 'numpy')\n",
    "\n",
    "\n",
    "def evaluate_A_and_diff(X):\n",
    "    results = []\n",
    "    A = tf.expand_dims(tf.squeeze(expr_A(X[:, 0], X[:, 1])), axis=-1)\n",
    "    A = tf.cast(A, dtype=DTYPE)\n",
    "    results.append(A)\n",
    "    dA_dx = tf.expand_dims(tf.squeeze(dexpr_A_dx(X[:, 0], X[:, 1])), axis=-1)\n",
    "    dA_dx = tf.cast(dA_dx, dtype=DTYPE)\n",
    "    results.append(dA_dx)\n",
    "    dA_dxx = tf.expand_dims(tf.squeeze(dexpr_A_dxx(X[:, 0], X[:, 1])), axis=-1)\n",
    "    dA_dxx = tf.cast(dA_dxx, dtype=DTYPE)\n",
    "    results.append(dA_dxx)\n",
    "    dA_dy = tf.expand_dims(tf.squeeze(dexpr_A_dy(X[:, 0], X[:, 1])), axis=-1)\n",
    "    dA_dy = tf.cast(dA_dy, dtype=DTYPE)\n",
    "    results.append(dA_dy)\n",
    "    print('dexpr_A_dyy(X[:, 0], X[:, 1]):\\n',dexpr_A_dyy(X[:, 0], X[:, 1]).shape)\n",
    "    dA_dyy = tf.expand_dims(tf.squeeze(dexpr_A_dyy(X[:, 0], X[:, 1])), axis=-1)\n",
    "    dA_dyy = tf.cast(dA_dyy, dtype=DTYPE)\n",
    "    results.append(dA_dyy)\n",
    "    for i,dA_ in enumerate(results):\n",
    "        if dA_.shape == (1,):\n",
    "            results[i]=dA_[0]\n",
    "    return results\n",
    "\n",
    "batch_size = 3\n",
    "line = tf.cast(tf.reshape(np.linspace(0,1,num=batch_size,endpoint=True),(batch_size,1)),dtype=DTYPE)\n",
    "boundary_L = tf.concat([tf.zeros((batch_size,1),dtype=DTYPE),line],axis=1)\n",
    "boundary_R = tf.concat([tf.ones((batch_size,1),dtype=DTYPE),line],axis=1)\n",
    "boundary_up = tf.concat([line,tf.ones((batch_size,1),dtype=DTYPE)],axis=1)\n",
    "boundary_bot = tf.concat([line,tf.zeros((batch_size,1),dtype=DTYPE)],axis=1)\n",
    "# true_function(boundary_L)-evaluate_A(boundary_L)\n",
    "test_boundary = boundary_bot\n",
    "A, dA_dx, dA_dxx, dA_dy, dA_dyy = evaluate_A_and_diff(test_boundary)\n",
    "print(dA_dyy+A)\n",
    "# print(dA_dyy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv_tsunami': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed45ddf3773bc83c4383a1a855f930bc53f0b7f7e989df0f3182f9bb62c1b41f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
