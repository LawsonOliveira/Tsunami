{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate - Problem 8\n",
    "## Description\n",
    "\n",
    "### Average time : 100 minutes\n",
    "\n",
    "### PDE\n",
    "We will try to find the best learning rate to the problem 8 of the article: https://ieeexplore.ieee.org/document/712178  \n",
    "\n",
    "$\\Delta \\psi(x,y) +\\psi(x,y)\\cdot\\frac{\\partial \\psi(x,y)}{\\partial y}= f(x,y)$ on $\\Omega = [0,1]^2$  \n",
    "where $f(x, y)=\\sin(\\pi x)(2-\\pi^2y^2+2y^3\\sin(\\pi x))$   \n",
    "\n",
    "### Boundary conditions    \n",
    "$\\psi(0,y)=\\psi(1,y)=\\psi(x,0)=0$ and $\\frac{\\partial \\psi}{\\partial y}(x,1)=2\\sin(\\pi x)$           \n",
    "\n",
    "### Loss function\n",
    "The loss to minimize here is $\\mathcal{L} = ||\\Delta \\psi(x,y) +\\psi(x,y)\\cdot\\frac{\\partial \\psi(x,y)}{\\partial y}-f(x,y) ||_2$  \n",
    "\n",
    "### Analytical solution\n",
    "The true function $\\psi$ should be $\\psi(x, y)=y^2sin(\\pi x)$  \n",
    "This solution is the same of the problem 7\n",
    "\n",
    "### Approximated solution\n",
    "We want find a solution $\\psi(x,y)=A(x,y)+F(x,y)N(x,y)$\n",
    "s.t:  \n",
    "$F(x,y)=\\sin(x-1)\\sin(y-1)\\sin(x)\\sin(y)$ \n",
    "$A(x,y)=y\\sin(\\pi x)$   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "# Jax libraries\n",
    "from jax import value_and_grad,vmap,jit,jacfwd\n",
    "from functools import partial \n",
    "from jax import random as jran\n",
    "from jax.example_libraries import optimizers as jax_opt\n",
    "from jax.nn import tanh, sigmoid, elu, relu, gelu\n",
    "from jax.lib import xla_bridge\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Others libraries\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    \"\"\"\n",
    "        Create a multilayer perceptron and initialize the neural network\n",
    "    Inputs :\n",
    "        A SEED number and the layers structure\n",
    "    \"\"\"\n",
    "    \n",
    "    # Class initialization\n",
    "    def __init__(self,SEED,layers):\n",
    "        self.key=jran.PRNGKey(SEED)\n",
    "        self.keys = jran.split(self.key,len(layers))\n",
    "        self.layers=layers\n",
    "        self.params = []\n",
    "\n",
    "    # Initialize the MLP weigths and bias\n",
    "    def MLP_create(self):\n",
    "        for layer in range(0, len(self.layers)-1):\n",
    "            in_size,out_size=self.layers[layer], self.layers[layer+1]\n",
    "            std_dev = jnp.sqrt(2/(in_size + out_size ))\n",
    "            weights=jran.truncated_normal(self.keys[layer], -2, 2, shape=(out_size, in_size), dtype=np.float32)*std_dev\n",
    "            bias=jran.truncated_normal(self.keys[layer], -1, 1, shape=(out_size, 1), dtype=np.float32).reshape((out_size,))\n",
    "            self.params.append((weights,bias))\n",
    "        return self.params\n",
    "        \n",
    "    # Evaluate a position XY using the neural network    \n",
    "    @partial(jit, static_argnums=(0,))    \n",
    "    def NN_evaluation(self,new_params, inputs):\n",
    "        for layer in range(0, len(new_params)-1):\n",
    "            weights, bias = new_params[layer]\n",
    "            inputs = gelu(jnp.add(jnp.dot(inputs, weights.T), bias))\n",
    "        weights, bias = new_params[-1]\n",
    "        output = jnp.dot(inputs, weights.T)+bias\n",
    "        return output\n",
    "    \n",
    "    # Get the key associated with the neural network\n",
    "    def get_key(self):\n",
    "        return self.key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two dimensional PDE operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDE_operators2d:\n",
    "    \"\"\"\n",
    "        Class with the most common operators used to solve PDEs\n",
    "    Input:\n",
    "        A function that we want to compute the respective operator\n",
    "    \"\"\"\n",
    "    \n",
    "    # Class initialization\n",
    "    def __init__(self,function):\n",
    "        self.function=function\n",
    "\n",
    "    # Compute the two dimensional laplacian\n",
    "    def laplacian_2d(self,params,inputs):\n",
    "        fun = lambda params,x,y: self.function(params, x,y)\n",
    "        @partial(jit)    \n",
    "        def action(params,x,y):\n",
    "            u_xx = jacfwd(jacfwd(fun, 1), 1)(params,x,y)\n",
    "            u_yy = jacfwd(jacfwd(fun, 2), 2)(params,x,y)\n",
    "            return u_xx + u_yy\n",
    "        vec_fun = vmap(action, in_axes = (None, 0, 0))\n",
    "        laplacian = vec_fun(params, inputs[:,0], inputs[:,1])\n",
    "        return laplacian\n",
    "\n",
    "    # Compute the partial derivative in x\n",
    "    @partial(jit, static_argnums=(0,))    \n",
    "    def du_dx(self,params,inputs):\n",
    "        fun = lambda params,x,y: self.function(params, x,y)\n",
    "        @partial(jit)    \n",
    "        def action(params,x,y):\n",
    "            u_x = jacfwd(fun, 1)(params,x,y)\n",
    "            return u_x\n",
    "        vec_fun = vmap(action, in_axes = (None, 0, 0))\n",
    "        return vec_fun(params, inputs[:,0], inputs[:,1])\n",
    "\n",
    "    # Compute the partial derivative in y\n",
    "    @partial(jit, static_argnums=(0,))    \n",
    "    def du_dy(self,params,inputs):\n",
    "        fun = lambda params,x,y: self.function(params, x,y)\n",
    "        @partial(jit)    \n",
    "        def action(params,x,y):\n",
    "            u_y = jacfwd(fun, 2)(params,x,y)\n",
    "            return u_y\n",
    "        vec_fun = vmap(action, in_axes = (None, 0, 0))\n",
    "        return vec_fun(params, inputs[:,0], inputs[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics Informed Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN:\n",
    "    \"\"\"\n",
    "    Solve a PDE using Physics Informed Neural Networks   \n",
    "    Input:\n",
    "        The evaluation function of the neural network\n",
    "    \"\"\"\n",
    "\n",
    "    # Class initialization\n",
    "    def __init__(self,NN_evaluation):\n",
    "        self.operators=PDE_operators2d(self.solution)\n",
    "        self.laplacian=self.operators.laplacian_2d\n",
    "        self.NN_evaluation=NN_evaluation\n",
    "        self.dsol_dy=self.operators.du_dy\n",
    "\n",
    "    # Definition of the function A(x,y) mentioned above\n",
    "    @partial(jit, static_argnums=(0,))    \n",
    "    def A_function(self,inputX,inputY):\n",
    "        return jnp.multiply(inputY,jnp.sin(jnp.pi*inputX)).reshape(-1,1)\n",
    "\n",
    "    # Definition of the function F(x,y) mentioned above   \n",
    "    @partial(jit, static_argnums=(0,))    \n",
    "    def F_function(self,inputX,inputY):\n",
    "        F1=jnp.multiply(jnp.sin(inputX),jnp.sin(inputX-jnp.ones_like(inputX)))\n",
    "        F2=jnp.multiply(jnp.sin(inputY),jnp.sin(inputY-jnp.ones_like(inputY)))\n",
    "        return jnp.multiply(F1,F2).reshape((-1,1))\n",
    "\n",
    "    # Definition of the function f(x,y) mentioned above   \n",
    "    @partial(jit, static_argnums=(0,))    \n",
    "    def target_function(self,inputs):\n",
    "        return jnp.multiply(jnp.sin(jnp.pi*inputs[:,0]),2-jnp.pi**2*inputs[:,1]**2+2*inputs[:,1]**3*jnp.sin(jnp.pi*inputs[:,0])).reshape(-1,1) \n",
    "\n",
    "    # Compute the solution of the PDE on the points (x,y)\n",
    "    @partial(jit, static_argnums=(0,))    \n",
    "    def solution(self,params,inputX,inputY):\n",
    "        inputs=jnp.column_stack((inputX,inputY))\n",
    "        NN = vmap(partial(jit(self.NN_evaluation), params))(inputs)\n",
    "        F=self.F_function(inputX,inputY)\n",
    "        A=self.A_function(inputX,inputY)\n",
    "        return jnp.add(jnp.multiply(F,NN),A).reshape(-1,1)\n",
    "\n",
    "    # Compute the loss function\n",
    "    @partial(jit, static_argnums=(0,))    \n",
    "    def loss_function(self,params,batch):\n",
    "        targets=self.target_function(batch)\n",
    "        laplacian=self.laplacian(params,batch).reshape(-1,1)\n",
    "        dsol_dy_values=self.dsol_dy(params,batch)[:,0].reshape((-1,1))\n",
    "        preds=laplacian+jnp.multiply(self.solution(params,batch[:,0],batch[:,1]),dsol_dy_values).reshape(-1,1)\n",
    "        return jnp.linalg.norm(preds-targets)\n",
    " \n",
    "    # Train step\n",
    "    @partial(jit, static_argnums=(0,))    \n",
    "    def train_step(self,i, opt_state, inputs):\n",
    "        params = get_params(opt_state)\n",
    "        loss, gradient = value_and_grad(self.loss_function)(params,inputs)\n",
    "        return loss, opt_update(i, gradient, opt_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network parameters\n",
    "SEED = 351\n",
    "n_features, n_targets = 2, 1            # Input and output dimension\n",
    "layers = [n_features,30,n_targets]      # Layers structure\n",
    "\n",
    "# Initialization\n",
    "NN_MLP=MLP(SEED,layers)                 \n",
    "params = NN_MLP.MLP_create()            # Create the MLP\n",
    "NN_eval=NN_MLP.NN_evaluation            # Evaluate function\n",
    "solver=PINN(NN_eval)\n",
    "key=NN_MLP.get_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "num_batches = 100000\n",
    "report_steps=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 8.0000001e-01 6.0000002e-01 4.0000001e-01 2.0000000e-01\n",
      " 1.0000000e-01 8.0000006e-02 6.0000002e-02 3.9999999e-02 2.0000000e-02\n",
      " 9.9999998e-03 7.9999994e-03 6.0000001e-03 3.9999997e-03 2.0000001e-03\n",
      " 1.0000000e-03 7.9999998e-04 6.0000003e-04 4.0000002e-04 1.9999999e-04\n",
      " 9.9999997e-05 7.9999998e-05 5.9999998e-05 3.9999999e-05 1.9999999e-05\n",
      " 9.9999997e-06 8.0000000e-06 5.9999998e-06 4.0000000e-06 2.0000000e-06\n",
      " 1.0000000e-06 8.0000001e-07 6.0000002e-07 4.0000000e-07 2.0000000e-07\n",
      " 1.0000000e-07 8.0000000e-08 5.9999998e-08 4.0000000e-08 2.0000000e-08\n",
      " 9.9999999e-09 7.9999998e-09 6.0000001e-09 3.9999999e-09 1.9999999e-09\n",
      " 9.9999997e-10 7.9999996e-10 5.9999999e-10 3.9999998e-10 2.0000000e-10]\n"
     ]
    }
   ],
   "source": [
    "init, end, interval_lenght = 0, 10, 5\n",
    "# Learning rate values\n",
    "intervals = jnp.array([jnp.linspace(10**(-i),10**(-i)/interval_lenght,interval_lenght) for i in range(init,end)])\n",
    "learning_rate = intervals.reshape(-1,1)[:,0]\n",
    "print(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving PDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch n°1000:  2.6494688987731934\n",
      "Epoch n°2000:  2.6326286792755127\n",
      "Epoch n°3000:  2.640900135040283\n",
      "Epoch n°4000:  2.6368932723999023\n",
      "Epoch n°5000:  3.3558623790740967\n",
      "Epoch n°6000:  3.3609070777893066\n",
      "Epoch n°7000:  3.3572230339050293\n",
      "Epoch n°8000:  3.3592758178710938\n",
      "Epoch n°9000:  3.3630776405334473\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_85068/1820847937.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mXY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjran\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mibatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/jax/example_libraries/optimizers.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(data, xs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mOptimizerState\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mlambda\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpacked_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtree_defs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     lambda data, xs: OptimizerState(xs[0], data[0], data[1]))  # type: ignore[index]\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main loop find the best learning rate\n",
    "counter=0\n",
    "min_index=jnp.inf\n",
    "min_loss_value = jnp.inf\n",
    "minimum_loss=[]\n",
    "\n",
    "# Create a file to save the learning rate\n",
    "file_data_learn=open('./learning_rate','w')\n",
    "file_data_learn.close()\n",
    "\n",
    "# Create a file to save the last value of the loss function\n",
    "file_data_loss=open('./loss_function','w')\n",
    "file_data_loss.close()\n",
    "\n",
    "for i in range(len(learning_rate)):\n",
    "    loss_history = []\n",
    "    opt_init, opt_update, get_params = jax_opt.adam(learning_rate[i])\n",
    "\n",
    "    NN_MLP=MLP(SEED,layers)                 \n",
    "    params = NN_MLP.MLP_create()            # Create the MLP\n",
    "    NN_eval=NN_MLP.NN_evaluation            # Evaluate function\n",
    "    solver=PINN(NN_eval)                    # Use PINN on the problem 8\n",
    "    key=NN_MLP.get_key()                    # Get the key of NN\n",
    "\n",
    "    opt_state = opt_init(params)            # Initialize opt_state\n",
    "    \n",
    "    for ibatch in range(0,num_batches):\n",
    "        ran_key, batch_key = jran.split(key)\n",
    "        XY_train = jran.uniform(batch_key, shape=(batch_size, n_features), minval=0, maxval=1)\n",
    "\n",
    "        loss, opt_state = solver.train_step(ibatch,opt_state, XY_train)\n",
    "        loss_history.append(float(loss))\n",
    "\n",
    "        if ibatch%report_steps==report_steps-1:\n",
    "            print(\"Epoch n°{}: \".format(ibatch+1), loss.item())\n",
    "\n",
    "    print(\"iteration\",i,\"of\",len(learning_rate)-1)\n",
    "    print(loss_history[num_batches-1],learning_rate[i])\n",
    "    minimum_loss.append(loss_history[num_batches-1])\n",
    "\n",
    "    # Get the index for the best learning rate\n",
    "    if loss_history[num_batches-1]<min_loss_value:\n",
    "        min_loss_value = loss_history[num_batches-1]\n",
    "        min_index=i\n",
    "        print('minimum value',minimum_loss[i])\n",
    "\n",
    "    # Save the learning rate\n",
    "    file_data_learn=open('./learning_rate','a')\n",
    "    file_data_learn.write(str(learning_rate[i])+',')\n",
    "    file_data_learn.close()\n",
    "\n",
    "    # Save the last value of the loss function\n",
    "    file_data_loss=open('./loss_function','a')\n",
    "    file_data_loss.write(str(loss_history[num_batches-1])+',')\n",
    "    file_data_loss.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot learning rate optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best learning rate = 8e-05\n"
     ]
    }
   ],
   "source": [
    "min_index=21\n",
    "learning_rate=[1.0,0.8,0.6,0.4,0.2,0.1,0.080000006,0.060000002,0.04,0.02,0.01,0.007999999,0.006,0.0039999997,0.002,0.001,0.0008,0.0006,0.00040000002,0.0002,1e-04,8e-05,6e-05,4e-05,2e-05,1e-05,8e-06,5.9999998e-06,4e-06,2e-06,1e-06,8e-07,6e-07,4e-07,2e-07]\n",
    "minimum_loss = [3.3589024543762207,1.6859272718429565,0.7435639500617981,0.18740606307983398,0.09280005842447281,0.08564911037683487,0.0627373605966568,0.05191640928387642,0.042144015431404114,0.01877341978251934,0.015574362128973007,0.014206845313310623,0.012948434799909592,0.0116304662078619,0.008996258489787579,0.007506238296627998,0.007247768342494965,0.006883973255753517,0.00629028957337141,0.005276193842291832,0.0048086014576256275,0.004483499098569155,0.004564367700368166,0.004636757075786591,0.006352274678647518,0.12315638363361359,0.28303778171539307,2.195760726928711,3.325516700744629,5.538702487945557,9.323655128479004,10.287568092346191,11.251932144165039,12.199068069458008,13.138975143432617]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "__=ax.plot(learning_rate,np.log10(minimum_loss),color='blue')\n",
    "__=ax.scatter(learning_rate[min_index],np.log10(minimum_loss[min_index]),color='red')\n",
    "legend = ax.legend([r'${\\rm learning \\ rate}$',r'${\\rm best \\ learning }$'])\n",
    "xlabel = ax.set_xlabel(r'${\\rm Learning \\ rate}$')\n",
    "ylabel = ax.set_ylabel(r'$\\log_{10}{\\rm (loss\\_function)}$')\n",
    "#title = ax.set_title(r'${\\rm Learning \\ rate \\ optimization}$')\n",
    "plt.show()\n",
    "print(\"best learning rate =\",learning_rate[min_index])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5030792b3492f6b12d94f1f48beca3d8e59ec05fd59d0aaaa48e684281ed297"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
